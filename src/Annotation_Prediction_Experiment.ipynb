{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "202a2725-48fa-48e9-828f-ffad016b5309",
   "metadata": {},
   "source": [
    "# Annotation Prediction Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8263ad1f-f610-474e-b197-63a3ffd84551",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "dcdadea3-0d0f-41b4-9584-150ae3b1e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7fae39-8f55-4147-bb29-45e3e63b6111",
   "metadata": {},
   "source": [
    "## Preparing data for BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c7c34bd8-bfb6-4661-a2e9-f9ae11617def",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/annotated_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "242dbb25-e0b2-42ea-a11d-531e4867f716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>followers</th>\n",
       "      <th>connections</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>content_links</th>\n",
       "      <th>media_type</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>hashtag_followers</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>reactions</th>\n",
       "      <th>comments</th>\n",
       "      <th>views</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>6484.0</td>\n",
       "      <td>500+</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>[['https://www.linkedin.com/in/ACoAABhNxDUB9IX...</td>\n",
       "      <td>article</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[['#verifiedresumes', 'https://www.linkedin.co...</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I count myself fortunate to have spent time wi...</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>6484.0</td>\n",
       "      <td>500+</td>\n",
       "      <td>10 months ago</td>\n",
       "      <td>[['https://lnkd.in/exKRtb6', 'https://lnkd.in/...</td>\n",
       "      <td>image</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No-one can be sure how America will ‘snap back...</td>\n",
       "      <td>Educational Resources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>6484.0</td>\n",
       "      <td>500+</td>\n",
       "      <td>11 months ago</td>\n",
       "      <td>[['https://lnkd.in/evGsZSH', 'https://lnkd.in/...</td>\n",
       "      <td>article</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>[['#apprenticeships', 'https://www.linkedin.co...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We've known since the Great Depression that si...</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>6484.0</td>\n",
       "      <td>500+</td>\n",
       "      <td>1 year ago</td>\n",
       "      <td>[['https://www.linkedin.com/feed/hashtag/?keyw...</td>\n",
       "      <td>video</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[['#apprenticeship', 'https://www.linkedin.com...</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Great to talk with Fox Business today on why c...</td>\n",
       "      <td>Trends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>6484.0</td>\n",
       "      <td>500+</td>\n",
       "      <td>2 years ago</td>\n",
       "      <td>[['https://www.linkedin.com/feed/hashtag/?keyw...</td>\n",
       "      <td>article</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[['#apprenticeship', 'https://www.linkedin.com...</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Where can an  #apprenticeship  take you ? Grea...</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  followers connections     time_spent  \\\n",
       "0      4     6484.0        500+   2 months ago   \n",
       "1     23     6484.0        500+  10 months ago   \n",
       "2     28     6484.0        500+  11 months ago   \n",
       "3     37     6484.0        500+     1 year ago   \n",
       "4     51     6484.0        500+    2 years ago   \n",
       "\n",
       "                                       content_links media_type  num_hashtags  \\\n",
       "0  [['https://www.linkedin.com/in/ACoAABhNxDUB9IX...    article             3   \n",
       "1  [['https://lnkd.in/exKRtb6', 'https://lnkd.in/...      image             0   \n",
       "2  [['https://lnkd.in/evGsZSH', 'https://lnkd.in/...    article             5   \n",
       "3  [['https://www.linkedin.com/feed/hashtag/?keyw...      video             1   \n",
       "4  [['https://www.linkedin.com/feed/hashtag/?keyw...    article             1   \n",
       "\n",
       "   hashtag_followers                                           hashtags  \\\n",
       "0                  0  [['#verifiedresumes', 'https://www.linkedin.co...   \n",
       "1                  0                                                 []   \n",
       "2                  0  [['#apprenticeships', 'https://www.linkedin.co...   \n",
       "3                  0  [['#apprenticeship', 'https://www.linkedin.com...   \n",
       "4                  0  [['#apprenticeship', 'https://www.linkedin.com...   \n",
       "\n",
       "   reactions  comments  views  \\\n",
       "0         22         2    NaN   \n",
       "1         22         1    NaN   \n",
       "2         10         0    NaN   \n",
       "3         31         4    NaN   \n",
       "4         27         1    NaN   \n",
       "\n",
       "                                             content                  label  \n",
       "0  I count myself fortunate to have spent time wi...                 Others  \n",
       "1  No-one can be sure how America will ‘snap back...  Educational Resources  \n",
       "2  We've known since the Great Depression that si...                 Others  \n",
       "3  Great to talk with Fox Business today on why c...                 Trends  \n",
       "4  Where can an  #apprenticeship  take you ? Grea...                 Others  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e4c7a-9ec8-4d58-9e62-0ad547308ea0",
   "metadata": {},
   "source": [
    "### Mapping Category label to index labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cfc3b752-ce4c-424c-a906-1b8029fda697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                 \n",
       "Others                    1131\n",
       "Interactive Promotions     107\n",
       "Trends                     104\n",
       "Professional Growth         98\n",
       "Events                      90\n",
       "Educational Resources       70\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['label']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1f5e2c6a-bb32-4e1c-aba9-e2698d9992ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"content\", \"label\"]]\n",
    "\n",
    "label_mapping = {\n",
    "    \"Professional Growth\": 1.0,\n",
    "    \"Events\": 2.0,\n",
    "    \"Interactive Promotions\": 3.0,\n",
    "    \"Educational Resources\": 4.0,\n",
    "    \"Trends\": 5.0,\n",
    "    \"Others\": 0.0\n",
    "}\n",
    "index_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "data[\"label\"] = data[\"label\"].map(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb4373d-2853-4625-9547-590a2c536c71",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c503db41-5e4b-4f42-b700-0c407f8b9478",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    data[\"content\"].tolist(), data[\"label\"].tolist(), test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7f953f-1fee-479a-8306-61afcbccf701",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "80fe2e2d-0ade-43c7-aaca-41359cb91505",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text, max_length=self.max_len, padding=\"max_length\",\n",
    "            truncation=True, return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7c64a-eac9-410b-aa4b-cc3375bec1ef",
   "metadata": {},
   "source": [
    "### Creating Dataloader and Handling Imbalance classes using WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "75ef6b69-d45e-4449-920d-a4f44e21f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = TextDataset(test_texts, test_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "11e5ccbf-fa35-4c58-b4d1-a3e16bb87e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = np.bincount([int(label) for label in train_labels])\n",
    "class_weights = 1.0 / class_counts\n",
    "sample_weights = [class_weights[int(label)] for label in train_labels]\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "2034b628-09fd-42eb-a01e-9feb0ec49ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, sampler=sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ea259f-a46c-4a58-9860-bcf81e89916a",
   "metadata": {},
   "source": [
    "## Model Fine tuning and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce15d7-4c3b-4eaa-af31-2f97acf25e8e",
   "metadata": {},
   "source": [
    "### Loading BERT and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0eff6b21-296e-483b-ad20-f9824e7891b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Bert Base Uncased\n",
    "#model = BertForSequenceClassification.from_pretrained(\n",
    "#    \"bert-base-uncased\", num_labels=len(label_mapping)\n",
    "#).to(device)\n",
    "\n",
    "# Distil Bert\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", \n",
    "                                                            num_labels=len(label_mapping)).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ded6b6fa-bfa3-41de-841e-75d8c6731ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\miniforge3\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weights, dtype=torch.float32).to(device))\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393a84e9-c764-421f-b423-a68bfe49605c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c7f2b6f8-13e8-4fa8-9aea-05851f93a520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 127.8043, Accuracy: 0.2812, F1-score: 0.2378\n",
      "Epoch 2, Loss: 69.0846, Accuracy: 0.6687, F1-score: 0.6095\n",
      "Epoch 3, Loss: 29.8155, Accuracy: 0.7711, F1-score: 0.6982\n",
      "Epoch 4, Loss: 13.7125, Accuracy: 0.8039, F1-score: 0.7236\n",
      "Epoch 5, Loss: 7.4639, Accuracy: 0.8445, F1-score: 0.7766\n",
      "Epoch 6, Loss: 4.9999, Accuracy: 0.8711, F1-score: 0.8335\n",
      "Epoch 7, Loss: 3.7229, Accuracy: 0.9187, F1-score: 0.9085\n",
      "Epoch 8, Loss: 2.6576, Accuracy: 0.9469, F1-score: 0.9430\n",
      "Epoch 9, Loss: 1.6060, Accuracy: 0.9695, F1-score: 0.9681\n",
      "Epoch 10, Loss: 1.2833, Accuracy: 0.9781, F1-score: 0.9775\n",
      "Epoch 11, Loss: 1.0592, Accuracy: 0.9859, F1-score: 0.9857\n",
      "Epoch 12, Loss: 0.9222, Accuracy: 0.9859, F1-score: 0.9857\n",
      "Epoch 13, Loss: 0.6827, Accuracy: 0.9891, F1-score: 0.9889\n",
      "Epoch 14, Loss: 0.5719, Accuracy: 0.9945, F1-score: 0.9945\n",
      "Epoch 15, Loss: 0.4931, Accuracy: 0.9914, F1-score: 0.9913\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss, total_correct, total_samples = 0, 0, 0\n",
    "    all_preds, all_labels = [], [] \n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, attention_mask, labels = batch[\"input_ids\"].to(device), batch[\"attention_mask\"].to(device), batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        total_correct += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Accuracy: {total_correct/total_samples:.4f}, F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a6d9a-8f19-4504-a2ad-6edf748451f4",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "7782be18-02a3-443d-9cb9-045e125a2da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids, attention_mask, labels = batch[\"input_ids\"].to(device), batch[\"attention_mask\"].to(device), batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "    print(f\"Test Accuracy: {acc:.4f}\")\n",
    "    print(f\"Test F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9775444c-7214-4515-b0d2-66643929c240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7531\n",
      "Test F1-score: 0.7555\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f521a12-cd63-4583-b9ba-2c8268365ef5",
   "metadata": {},
   "source": [
    "## Model Saving, Loading and Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b347b2-cbae-42e9-847f-69eed1fd1997",
   "metadata": {},
   "source": [
    "### Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4b605f4f-ffed-4063-9d8c-216d1d81aea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/Distil_bert_post_classifier_v1.pth\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"../models/Distil_bert_post_classifier_v1.pth\"\n",
    "tokenizer_save_path = \"../models/Distil_bert_tokenizer\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "tokenizer.save_pretrained(tokenizer_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f56beca-8cc9-49fa-af7f-6a5cc5d96841",
   "metadata": {},
   "source": [
    "### Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "12cf6081-ad5e-4ab9-b98b-f115b07f9525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_text(text, model, tokenizer, device, index_label_mapping):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(\n",
    "        text, max_length=128, padding=\"max_length\",\n",
    "        truncation=True, return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids, attention_mask = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=1).cpu().detach().numpy()\n",
    "\n",
    "    return index_label_mapping[preds[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f189c2ee-2a60-4319-ab27-08dedde553d0",
   "metadata": {},
   "source": [
    "### Loading Saved Model from local repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "88b3998a-e6e6-41b2-98af-4ed51c4641d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_mapping)).to(device)\n",
    "loaded_model.load_state_dict(torch.load(model_save_path))\n",
    "loaded_model.eval()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(tokenizer_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a8e01-aba6-4455-b7e4-aad58629307d",
   "metadata": {},
   "source": [
    "### Uploading Model on Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "9ff20efc-fcbb-49ab-b68b-c71451da5578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a351bd0aad049099ca65271a6050e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7014c4af5e444580ab635dad97bbd4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mujtabakk/DistilBert-LinkedIn-Posts-Classfication/commit/a760ca28eda3e1c4a37c5b0df1fb3c5614cd17f6', commit_message='Upload DistilBertForSequenceClassification', commit_description='', oid='a760ca28eda3e1c4a37c5b0df1fb3c5614cd17f6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/mujtabakk/DistilBert-LinkedIn-Posts-Classfication', endpoint='https://huggingface.co', repo_type='model', repo_id='mujtabakk/DistilBert-LinkedIn-Posts-Classfication'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebook_login()\n",
    "\n",
    "model.push_to_hub(\"mujtabakk/DistilBert-LinkedIn-Posts-Classfication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8f041b47-1975-4fda-bd86-7e6f55873216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mujtabakk/DistilBert-LinkedIn-Posts-Classification/commit/e1618695a250d3ecced329675b23ae0db758718b', commit_message='Upload tokenizer', commit_description='', oid='e1618695a250d3ecced329675b23ae0db758718b', pr_url=None, repo_url=RepoUrl('https://huggingface.co/mujtabakk/DistilBert-LinkedIn-Posts-Classification', endpoint='https://huggingface.co', repo_type='model', repo_id='mujtabakk/DistilBert-LinkedIn-Posts-Classification'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"mujtabakk/DistilBert-LinkedIn-Posts-Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c0252-f20c-47b2-b262-a3f6b847abb2",
   "metadata": {},
   "source": [
    "### Loading model from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "662dc0c5-87a9-413d-b6f9-9391a97c78bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mujtabakk/DistilBert-LinkedIn-Posts-Classfication\"\n",
    "loaded_model2 = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"../models/Distil_bert_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dfd62d-1b7e-417a-93e9-e0d88b6b7a56",
   "metadata": {},
   "source": [
    "### Example Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c4498-440f-4ab9-afbd-b53927e02c4b",
   "metadata": {},
   "source": [
    "#### Gold Label: Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1a83ab04-be9c-404e-b142-05718fec15cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: Events\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Join us for the Annual Tech Innovation Summit on November 15th!\"\n",
    "predicted_label = predict_single_text(sample_text, loaded_model2, tokenizer, device, index_label_mapping)\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfff6277-bb01-47d1-b1ba-0792011f5bf4",
   "metadata": {},
   "source": [
    "#### Gold Label: Professional Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "91231034-ad72-4689-ae8c-d2617b0cf5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: Others\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Just got a job offer from Google and Microsoft—Google offers better work-life balance, while Microsoft has better food. Which one should I choose?\"\n",
    "predicted_label = predict_single_text(sample_text, loaded_model2, tokenizer, device, index_label_mapping)\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c92062-7ed9-4870-8730-c5b828cbb0bb",
   "metadata": {},
   "source": [
    "#### Gold Label: Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "919ff0a5-cfb3-4241-9585-7417f46cc0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: Events\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Get free tickets to my amazing lecture that teaches you about deep neural networks at the PyCon event.\"\n",
    "predicted_label = predict_single_text(sample_text, loaded_model2, tokenizer, device, index_label_mapping)\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504bca14-c81b-469c-8258-f234e2cbf0d1",
   "metadata": {},
   "source": [
    "#### Gold Label: Educational Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "40b433fe-fd9c-4d2e-be8d-e1fd9e6bdf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: Others\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Just completed a data science bootcamp! Amazing learning experience, but I think traditional degrees still have their advantages.\"\n",
    "predicted_label = predict_single_text(sample_text, loaded_model2, tokenizer, device, index_label_mapping)\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f84f58d-f3ce-4732-9f35-3acd963661f1",
   "metadata": {},
   "source": [
    "#### Gold Label: Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fc8264ff-e383-4ed2-a6e4-4bace3daf457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: Others\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"The latest breakthroughs in AI-generated art are stunning—but will they replace human creativity?\"\n",
    "predicted_label = predict_single_text(sample_text, loaded_model2, tokenizer, device, index_label_mapping)\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431629f3-6b37-4fd7-be1a-d41c908ef854",
   "metadata": {},
   "source": [
    "#### Gold Label: Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7d880f1d-b0d0-4d39-bce6-865e745e64d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: Trends\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"The rise of remote work is reshaping the future of the workplace\"\n",
    "predicted_label = predict_single_text(sample_text, loaded_model2, tokenizer, device, index_label_mapping)\n",
    "print(f\"Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ec99c1-4d51-4faf-9cbd-7c13ea18a496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
